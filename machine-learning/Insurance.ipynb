{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sought-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "iraqi-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = pd.read_csv(\"insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "painted-blank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.207025</td>\n",
       "      <td>30.663397</td>\n",
       "      <td>1.094918</td>\n",
       "      <td>13270.422265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.049960</td>\n",
       "      <td>6.098187</td>\n",
       "      <td>1.205493</td>\n",
       "      <td>12110.011237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1121.873900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.296250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4740.287150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9382.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>34.693750</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16639.912515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.130000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>63770.428010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          bmi     children       charges\n",
       "count  1338.000000  1338.000000  1338.000000   1338.000000\n",
       "mean     39.207025    30.663397     1.094918  13270.422265\n",
       "std      14.049960     6.098187     1.205493  12110.011237\n",
       "min      18.000000    15.960000     0.000000   1121.873900\n",
       "25%      27.000000    26.296250     0.000000   4740.287150\n",
       "50%      39.000000    30.400000     1.000000   9382.033000\n",
       "75%      51.000000    34.693750     2.000000  16639.912515\n",
       "max      64.000000    53.130000     5.000000  63770.428010"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "periodic-coordinator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "insurance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cardiovascular-print",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "healthy-shell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance['age'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "african-landing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       yes\n",
       " 1        no\n",
       " 2        no\n",
       " 3        no\n",
       " 4        no\n",
       "        ... \n",
       " 1333     no\n",
       " 1334     no\n",
       " 1335     no\n",
       " 1336     no\n",
       " 1337    yes\n",
       " Name: smoker, Length: 1338, dtype: object,\n",
       " 0       19\n",
       " 1       18\n",
       " 2       28\n",
       " 3       33\n",
       " 4       32\n",
       "         ..\n",
       " 1333    50\n",
       " 1334    18\n",
       " 1335    18\n",
       " 1336    21\n",
       " 1337    61\n",
       " Name: age, Length: 1338, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance['smoker'],insurance['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-queue",
   "metadata": {},
   "source": [
    "#### One hot encoding to turn categorical variable unto numerical variables. Just for a Single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "advisory-gibson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex_female  sex_male\n",
       "0              1         0\n",
       "1              0         1\n",
       "2              0         1\n",
       "3              0         1\n",
       "4              0         1\n",
       "...          ...       ...\n",
       "1333           0         1\n",
       "1334           1         0\n",
       "1335           1         0\n",
       "1336           1         0\n",
       "1337           1         0\n",
       "\n",
       "[1338 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(insurance['sex'],prefix=\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-crawford",
   "metadata": {},
   "source": [
    "#### One hot encoding to turn categorical variable unto numerical variables. For all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "operating-australian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0   19  27.900         0  16884.92400           1         0          0   \n",
       "1   18  33.770         1   1725.55230           0         1          1   \n",
       "2   28  33.000         3   4449.46200           0         1          1   \n",
       "3   33  22.705         0  21984.47061           0         1          1   \n",
       "4   32  28.880         0   3866.85520           0         1          1   \n",
       "\n",
       "   smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0           1                 0                 0                 0   \n",
       "1           0                 0                 0                 1   \n",
       "2           0                 0                 0                 1   \n",
       "3           0                 0                 1                 0   \n",
       "4           0                 0                 1                 0   \n",
       "\n",
       "   region_southwest  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_one_hot = pd.get_dummies(insurance)\n",
    "insurance_one_hot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-rhythm",
   "metadata": {},
   "source": [
    "#### Create X and y values, features and labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-biography",
   "metadata": {},
   "source": [
    "#### Create a training set and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-sarah",
   "metadata": {},
   "source": [
    "#### then build a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "manual-record",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0   19  27.900         0           1         0          0           1   \n",
       "1   18  33.770         1           0         1          1           0   \n",
       "2   28  33.000         3           0         1          1           0   \n",
       "3   33  22.705         0           0         1          1           0   \n",
       "4   32  28.880         0           0         1          1           0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 0                 1  \n",
       "1                 0                 0                 1                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 0                 1                 0                 0  \n",
       "4                 0                 1                 0                 0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = insurance_one_hot.drop(\"charges\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "spare-yahoo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16884.92400\n",
       "1     1725.55230\n",
       "2     4449.46200\n",
       "3    21984.47061\n",
       "4     3866.85520\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = insurance_one_hot[\"charges\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-delhi",
   "metadata": {},
   "source": [
    "### Using `scikit learn` for train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "detected-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "married-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "shaped-exhibit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 268, 1070, 268)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "alike-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "indoor-poster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      " 1/34 [..............................] - ETA: 0s - loss: 13143.3770 - mae: 13143.3770WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0001s vs `on_train_batch_begin` time: 0.0020s). Check your callbacks.\n",
      "34/34 [==============================] - 0s 356us/step - loss: 8627.7109 - mae: 8627.7109\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 236us/step - loss: 7879.1143 - mae: 7879.1143\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 287us/step - loss: 7589.4102 - mae: 7589.4102\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 292us/step - loss: 7824.0122 - mae: 7824.0122\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 301us/step - loss: 7657.5898 - mae: 7657.5898\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 289us/step - loss: 7649.4644 - mae: 7649.4644\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 587us/step - loss: 7549.8232 - mae: 7549.8232\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 296us/step - loss: 7721.1250 - mae: 7721.1250\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 369us/step - loss: 7626.3506 - mae: 7626.3506\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 221us/step - loss: 7700.9839 - mae: 7700.9839\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: 7556.8857 - mae: 7556.8857\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 297us/step - loss: 7707.2788 - mae: 7707.2788\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 290us/step - loss: 7690.4849 - mae: 7690.4849\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 587us/step - loss: 7725.4551 - mae: 7725.4551\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 292us/step - loss: 7661.6655 - mae: 7661.6655\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 7691.1675 - mae: 7691.1675\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 371us/step - loss: 7564.9985 - mae: 7564.9985\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 299us/step - loss: 7829.6978 - mae: 7829.6978\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 290us/step - loss: 7610.7554 - mae: 7610.7554\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 289us/step - loss: 7959.4814 - mae: 7959.4814\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 588us/step - loss: 7569.6313 - mae: 7569.6313\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 299us/step - loss: 7776.4038 - mae: 7776.4038\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 291us/step - loss: 7727.3374 - mae: 7727.3374\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: 7510.7837 - mae: 7510.7837\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 7717.6064 - mae: 7717.6064\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 581us/step - loss: 7690.4814 - mae: 7690.4814\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 297us/step - loss: 7583.3447 - mae: 7583.3447\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 7502.8022 - mae: 7502.8022\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: 7616.4009 - mae: 7616.4009\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 7609.9634 - mae: 7609.9634\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 292us/step - loss: 7570.5151 - mae: 7570.5151\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 380us/step - loss: 7444.9932 - mae: 7444.9932\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 505us/step - loss: 7411.9912 - mae: 7411.9912\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: 7366.4971 - mae: 7366.4971\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: 7453.1929 - mae: 7453.1929\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: 7588.8027 - mae: 7588.8027\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 299us/step - loss: 7589.0513 - mae: 7589.0513\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: 7596.7935 - mae: 7596.7935\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 292us/step - loss: 7559.4512 - mae: 7559.4512\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 7385.2988 - mae: 7385.2988\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 292us/step - loss: 7725.8945 - mae: 7725.8945\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 598us/step - loss: 7553.2676 - mae: 7553.2676\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 287us/step - loss: 7654.9331 - mae: 7654.9331\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 585us/step - loss: 7469.3696 - mae: 7469.3696\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 299us/step - loss: 7466.2114 - mae: 7466.2114\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 582us/step - loss: 7625.9800 - mae: 7625.9800\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 7447.4951 - mae: 7447.4951\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 147us/step - loss: 7500.5635 - mae: 7500.5635\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 7555.7920 - mae: 7555.7920\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: 7487.9395 - mae: 7487.9395\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: 7384.9619 - mae: 7384.9619\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 594us/step - loss: 7483.7314 - mae: 7483.7314\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 289us/step - loss: 7542.3975 - mae: 7542.3975\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 384us/step - loss: 7229.0366 - mae: 7229.0366\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 503us/step - loss: 7506.2715 - mae: 7506.2715\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 7274.6035 - mae: 7274.6035\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 289us/step - loss: 7421.0181 - mae: 7421.0181\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: 7360.1504 - mae: 7360.1504\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 285us/step - loss: 7583.5952 - mae: 7583.5952\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: 7474.7241 - mae: 7474.7241\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 300us/step - loss: 7586.7344 - mae: 7586.7344\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 7276.7896 - mae: 7276.7896\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: 7345.2334 - mae: 7345.2334\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 297us/step - loss: 7455.0776 - mae: 7455.0776\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 291us/step - loss: 7613.7646 - mae: 7613.7646\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 301us/step - loss: 7325.4253 - mae: 7325.4253\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 288us/step - loss: 7247.4663 - mae: 7247.4663\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 593us/step - loss: 7413.3862 - mae: 7413.3862\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 389us/step - loss: 7377.3970 - mae: 7377.3970\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 302us/step - loss: 7474.0596 - mae: 7474.0596\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 293us/step - loss: 7337.4204 - mae: 7337.4204\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 579us/step - loss: 7293.1152 - mae: 7293.1152\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 7395.9824 - mae: 7395.9824\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: 7450.3657 - mae: 7450.3657\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: 7133.6582 - mae: 7133.6582\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 283us/step - loss: 7102.6045 - mae: 7102.6045\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 192us/step - loss: 7320.6416 - mae: 7320.6416\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: 7130.8564 - mae: 7130.8564\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 289us/step - loss: 7303.5703 - mae: 7303.5703\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: 7065.5020 - mae: 7065.5020\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 595us/step - loss: 7276.3750 - mae: 7276.3750\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 582us/step - loss: 7145.3237 - mae: 7145.3237\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 403us/step - loss: 7402.6685 - mae: 7402.6685\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 476us/step - loss: 7364.1973 - mae: 7364.1973\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: 7392.0552 - mae: 7392.0552\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 591us/step - loss: 7389.9155 - mae: 7389.9155\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 291us/step - loss: 7280.3438 - mae: 7280.3438\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: 7266.7437 - mae: 7266.7437\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 593us/step - loss: 7464.2319 - mae: 7464.2319\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 402us/step - loss: 7234.3477 - mae: 7234.3477\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 192us/step - loss: 7386.0029 - mae: 7386.0029\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 577us/step - loss: 7363.0532 - mae: 7363.0532\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: 7292.4351 - mae: 7292.4351\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: 7200.2461 - mae: 7200.2461\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 7523.8735 - mae: 7523.8735\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 300us/step - loss: 7351.0337 - mae: 7351.0337\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 282us/step - loss: 7225.7710 - mae: 7225.7710\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 408us/step - loss: 7319.7148 - mae: 7319.7148\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 476us/step - loss: 7260.7988 - mae: 7260.7988\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 297us/step - loss: 7271.0000 - mae: 7271.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a7961b4970>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "insurance_model.compile(loss = tf.keras.losses.mae,\n",
    "                       optimizer = tf.keras.optimizers.SGD(),\n",
    "                       metrics = [\"mae\"])\n",
    "\n",
    "insurance_model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-strategy",
   "metadata": {},
   "source": [
    "##### Check the result of insurance model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "norman-portrait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 0s/step - loss: 8443.0381 - mae: 8443.0381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8443.0380859375, 8443.0380859375]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "negative-musical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9575.4421, 13346.089736364485)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.median(), y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-camel",
   "metadata": {},
   "source": [
    "#### Right now our model looks like not performaing well. Lets try and improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-water",
   "metadata": {},
   "source": [
    "#### Another `model_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "necessary-lodging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_34 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 354us/step - loss: nan - mae: nan        \n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: nan - mae: nan\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: nan - mae: nan\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: nan - mae: nan\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: nan - mae: nan\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 588us/step - loss: nan - mae: nan\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 300us/step - loss: nan - mae: nan\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 296us/step - loss: nan - mae: nan\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 593us/step - loss: nan - mae: nan\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 283us/step - loss: nan - mae: nan\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 297us/step - loss: nan - mae: nan\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 286us/step - loss: nan - mae: nan\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: nan - mae: nan\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 589us/step - loss: nan - mae: nan\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 299us/step - loss: nan - mae: nan\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 466us/step - loss: nan - mae: nan\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 421us/step - loss: nan - mae: nan\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: nan - mae: nan\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: nan - mae: nan\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 285us/step - loss: nan - mae: nan\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: nan - mae: nan\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - ETA: 0s - loss: nan - mae: na - 0s 295us/step - loss: nan - mae: nan\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 285us/step - loss: nan - mae: nan\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 296us/step - loss: nan - mae: nan\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 586us/step - loss: nan - mae: nan\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: nan - mae: nan\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: nan - mae: nan\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 299us/step - loss: nan - mae: nan\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: nan - mae: nan\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: nan - mae: nan\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: nan - mae: nan\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: nan - mae: nan\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: nan - mae: nan\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: nan - mae: nan\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 296us/step - loss: nan - mae: nan\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 575us/step - loss: nan - mae: nan\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 302us/step - loss: nan - mae: nan\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 470us/step - loss: nan - mae: nan\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: nan - mae: nan\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 284us/step - loss: nan - mae: nan\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 589us/step - loss: nan - mae: nan\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: nan - mae: nan\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 595us/step - loss: nan - mae: nan\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 287us/step - loss: nan - mae: nan\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 586us/step - loss: nan - mae: nan\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 300us/step - loss: nan - mae: nan\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 589us/step - loss: nan - mae: nan\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: nan - mae: nan\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 299us/step - loss: nan - mae: nan\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 587us/step - loss: nan - mae: nan\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 287us/step - loss: nan - mae: nan\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 483us/step - loss: nan - mae: nan\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 306us/step - loss: nan - mae: nan\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 284us/step - loss: nan - mae: nan\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 593us/step - loss: nan - mae: nan\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 290us/step - loss: nan - mae: nan\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: nan - mae: nan\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 594us/step - loss: nan - mae: nan\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: nan - mae: nan\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 103us/step - loss: nan - mae: nan\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 301us/step - loss: nan - mae: nan\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: nan - mae: nan\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 581us/step - loss: nan - mae: nan\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 292us/step - loss: nan - mae: nan\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: nan - mae: nan\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 595us/step - loss: nan - mae: nan\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: nan - mae: nan\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 297us/step - loss: nan - mae: nan\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 305us/step - loss: nan - mae: nan\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: nan - mae: nan\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 578us/step - loss: nan - mae: nan\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 297us/step - loss: nan - mae: nan\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 289us/step - loss: nan - mae: nan\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 600us/step - loss: nan - mae: nan\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 283us/step - loss: nan - mae: nan\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 296us/step - loss: nan - mae: nan\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 593us/step - loss: nan - mae: nan\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: nan - mae: nan\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: nan - mae: nan\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: nan - mae: nan\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 301us/step - loss: nan - mae: nan\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 383us/step - loss: nan - mae: nan\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: nan - mae: nan\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 291us/step - loss: nan - mae: nan\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 602us/step - loss: nan - mae: nan\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 283us/step - loss: nan - mae: nan\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: nan - mae: nan\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 301us/step - loss: nan - mae: nan\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 297us/step - loss: nan - mae: nan\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 286us/step - loss: nan - mae: nan\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 289us/step - loss: nan - mae: nan\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 301us/step - loss: nan - mae: nan\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 586us/step - loss: nan - mae: nan\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: nan - mae: nan\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: nan - mae: nan\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 291us/step - loss: nan - mae: nan\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: nan - mae: nan\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 597us/step - loss: nan - mae: nan\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 292us/step - loss: nan - mae: nan\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: nan - mae: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a79a643340>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100), # Added an extra layer\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "## Remember optimizers start with caps\n",
    "insurance_model_2.compile(loss = tf.keras.losses.mae,\n",
    "                       #optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                       optimizer = tf.keras.optimizers.SGD(),\n",
    "                       metrics = [\"mae\"])\n",
    "\n",
    "insurance_model_2.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "still-engine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_37 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 651us/step - loss: 8716.4688 - mae: 8716.4688\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7883.9180 - mae: 7883.9180\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7605.7480 - mae: 7605.7480\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7606.8955 - mae: 7606.8955\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7703.9536 - mae: 7703.9536\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7643.4917 - mae: 7643.4917\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7546.4575 - mae: 7546.4575\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7736.8062 - mae: 7736.8062\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 651us/step - loss: 7548.9170 - mae: 7548.9170\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7731.2900 - mae: 7731.2900\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7531.5366 - mae: 7531.5366\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7605.1104 - mae: 7605.1104\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7694.1284 - mae: 7694.1284\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7625.8013 - mae: 7625.8013\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7555.8833 - mae: 7555.8833\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7698.8979 - mae: 7698.8979\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 191us/step - loss: 7666.6304 - mae: 7666.6304\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7778.6138 - mae: 7778.6138\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7583.2993 - mae: 7583.2993\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7869.9590 - mae: 7869.9590\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7513.9482 - mae: 7513.9482\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7761.0015 - mae: 7761.0015\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7740.5117 - mae: 7740.5117\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7530.3687 - mae: 7530.3687\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 191us/step - loss: 7576.2061 - mae: 7576.2061\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7599.8784 - mae: 7599.8784\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7572.0386 - mae: 7572.0386\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7426.6216 - mae: 7426.6216\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7675.7104 - mae: 7675.7104\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7702.6479 - mae: 7702.6479\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7545.1353 - mae: 7545.1353\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 8081.9399 - mae: 8081.939 - 0s 0s/step - loss: 7426.8120 - mae: 7426.8120\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 191us/step - loss: 7449.6680 - mae: 7449.6680\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7540.8198 - mae: 7540.8198\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7380.7266 - mae: 7380.7266\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7387.5688 - mae: 7387.5688\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7522.3076 - mae: 7522.3076\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7363.2339 - mae: 7363.2339\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7535.3979 - mae: 7535.3979\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7554.7256 - mae: 7554.7256\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 191us/step - loss: 7746.1567 - mae: 7746.1567\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7382.2271 - mae: 7382.2271\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7604.8433 - mae: 7604.8433\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7390.5835 - mae: 7390.5835\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7513.8545 - mae: 7513.8545\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7324.6919 - mae: 7324.6919\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7485.2144 - mae: 7485.2144\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7320.3647 - mae: 7320.3647\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 191us/step - loss: 7540.9092 - mae: 7540.9092\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7484.5566 - mae: 7484.5566\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7411.3569 - mae: 7411.3569\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7484.2041 - mae: 7484.2041\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7417.7090 - mae: 7417.7090\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7248.3765 - mae: 7248.3765\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7204.1211 - mae: 7204.1211\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 651us/step - loss: 7234.5830 - mae: 7234.5830\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7407.1133 - mae: 7407.1133\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7472.2505 - mae: 7472.2505\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7642.4937 - mae: 7642.4937\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7479.7480 - mae: 7479.7480\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7478.2754 - mae: 7478.2754\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7396.4023 - mae: 7396.4023\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7355.8115 - mae: 7355.8115\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 651us/step - loss: 7377.2812 - mae: 7377.2812\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7596.6357 - mae: 7596.6357\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7083.9956 - mae: 7083.9956\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7237.0747 - mae: 7237.0747\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7578.5786 - mae: 7578.5786\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7541.5898 - mae: 7541.5898\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7687.0547 - mae: 7687.0547\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7365.9795 - mae: 7365.9795\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 651us/step - loss: 7501.0122 - mae: 7501.0122\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 460us/step - loss: 7284.1431 - mae: 7284.1431\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7520.9541 - mae: 7520.9541\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7302.8018 - mae: 7302.8018\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7100.1821 - mae: 7100.1821\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7282.4155 - mae: 7282.4155\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7493.8120 - mae: 7493.8120\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7399.8237 - mae: 7399.8237\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 191us/step - loss: 7230.1870 - mae: 7230.1870\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7250.1104 - mae: 7250.1104\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7161.5640 - mae: 7161.5640\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7488.6411 - mae: 7488.6411\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7406.6655 - mae: 7406.6655\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7539.6465 - mae: 7539.6465\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7482.7041 - mae: 7482.7041\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7345.7700 - mae: 7345.7700\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 191us/step - loss: 7303.8188 - mae: 7303.8188\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7470.3564 - mae: 7470.3564\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7025.2329 - mae: 7025.2329\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7307.1636 - mae: 7307.1636\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7269.0854 - mae: 7269.0854\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7511.9287 - mae: 7511.9287\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7191.7705 - mae: 7191.7705\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7167.2295 - mae: 7167.2295\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 191us/step - loss: 7220.9238 - mae: 7220.9238\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7034.2202 - mae: 7034.2207\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7572.9326 - mae: 7572.9326\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7255.1323 - mae: 7255.1323\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7171.9634 - mae: 7171.9634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a79a89b700>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Adding extra layer gives nan value \n",
    "\n",
    "insurance_model_3 = tf.keras.Sequential([\n",
    "    #tf.keras.layers.Dense(100), # Remove extra layer\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "## Remember optimizers start with caps\n",
    "insurance_model_3.compile(loss = tf.keras.losses.mae,\n",
    "                       #optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                       optimizer = tf.keras.optimizers.SGD(),\n",
    "                       metrics = [\"mae\"])\n",
    "\n",
    "insurance_model_3.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "conditional-bridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_51 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 348us/step - loss: 13309.4980 - mae: 13309.4980\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 291us/step - loss: 13135.5879 - mae: 13135.5879\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 299us/step - loss: 12781.3779 - mae: 12781.3779\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 289us/step - loss: 12094.7891 - mae: 12094.7891\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 299us/step - loss: 10959.2314 - mae: 10959.2314\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: 9520.9844 - mae: 9520.9844\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 8196.6934 - mae: 8196.6934\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: 7551.1470 - mae: 7551.1470\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: 7440.3896 - mae: 7440.3896\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 584us/step - loss: 7419.1562 - mae: 7419.1562\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 300us/step - loss: 7400.5405 - mae: 7400.5405\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 583us/step - loss: 7378.5474 - mae: 7378.5474\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 296us/step - loss: 7357.9824 - mae: 7357.9824\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 588us/step - loss: 7335.8765 - mae: 7335.8765\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: 7316.8271 - mae: 7316.8271\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 592us/step - loss: 7294.0737 - mae: 7294.0737\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 286us/step - loss: 7274.1724 - mae: 7274.1724\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 595us/step - loss: 7250.7046 - mae: 7250.7046\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 300us/step - loss: 7228.6611 - mae: 7228.6611\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 578us/step - loss: 7205.0356 - mae: 7205.0356\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 291us/step - loss: 7185.3857 - mae: 7185.3857\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 592us/step - loss: 7158.8462 - mae: 7158.8462\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 7133.7012 - mae: 7133.7012\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 592us/step - loss: 7108.7686 - mae: 7108.7686\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 285us/step - loss: 7089.8701 - mae: 7089.8701\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 299us/step - loss: 7058.6221 - mae: 7058.6221\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 542us/step - loss: 7029.4995 - mae: 7029.4995\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 301us/step - loss: 7001.0444 - mae: 7001.0444\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 290us/step - loss: 6972.2778 - mae: 6972.2778\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: 6945.0132 - mae: 6945.0132\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 588us/step - loss: 6913.0103 - mae: 6913.0103\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 302us/step - loss: 6884.8618 - mae: 6884.8618\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 591us/step - loss: 6852.0444 - mae: 6852.0444\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 286us/step - loss: 6819.4805 - mae: 6819.4805\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 598us/step - loss: 6785.2500 - mae: 6785.2500\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 283us/step - loss: 6750.0220 - mae: 6750.0220\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 599us/step - loss: 6712.5381 - mae: 6712.5381\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 297us/step - loss: 6680.1606 - mae: 6680.1606\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 576us/step - loss: 6640.8979 - mae: 6640.8979\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: 6604.5977 - mae: 6604.5977\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 299us/step - loss: 6571.3213 - mae: 6571.3213\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 6546.3208 - mae: 6546.3208\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 6514.0781 - mae: 6514.0781\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: 6493.7314 - mae: 6493.7314\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 308us/step - loss: 6480.2632 - mae: 6480.2632\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 282us/step - loss: 6462.3701 - mae: 6462.3701\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 290us/step - loss: 6445.1514 - mae: 6445.1514\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 591us/step - loss: 6430.7744 - mae: 6430.7744\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 296us/step - loss: 6417.5454 - mae: 6417.5454\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 594us/step - loss: 6403.3428 - mae: 6403.3428\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: 6389.4385 - mae: 6389.4385\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 578us/step - loss: 6376.9819 - mae: 6376.9819\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 294us/step - loss: 6362.8491 - mae: 6362.8491\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 329us/step - loss: 6348.3823 - mae: 6348.3823\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 286us/step - loss: 6334.5718 - mae: 6334.5718\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 293us/step - loss: 6320.4287 - mae: 6320.4287\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 598us/step - loss: 6306.8970 - mae: 6306.8970\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 288us/step - loss: 6292.2129 - mae: 6292.2129\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6277.0356 - mae: 6277.0356\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 306us/step - loss: 6265.7759 - mae: 6265.7759\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 588us/step - loss: 6245.4243 - mae: 6245.4243\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 290us/step - loss: 6232.3784 - mae: 6232.3784\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 580us/step - loss: 6213.5063 - mae: 6213.5063\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 306us/step - loss: 6196.2515 - mae: 6196.2515\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 581us/step - loss: 6178.4077 - mae: 6178.4077\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 288us/step - loss: 6160.4819 - mae: 6160.4819\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 596us/step - loss: 6147.2739 - mae: 6147.2739\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 286us/step - loss: 6124.5005 - mae: 6124.5005\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 593us/step - loss: 6107.0801 - mae: 6107.0801\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 303us/step - loss: 6085.9868 - mae: 6085.9868\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 575us/step - loss: 6066.0933 - mae: 6066.0933\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 307us/step - loss: 6045.1714 - mae: 6045.1714\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 579us/step - loss: 6031.2109 - mae: 6031.2109\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 298us/step - loss: 6001.0474 - mae: 6001.0474\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 585us/step - loss: 5979.3599 - mae: 5979.3599\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 297us/step - loss: 5963.3892 - mae: 5963.3892\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 589us/step - loss: 5932.0864 - mae: 5932.0864\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 286us/step - loss: 5906.1040 - mae: 5906.1040\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 592us/step - loss: 5880.5322 - mae: 5880.5322\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 291us/step - loss: 5851.3862 - mae: 5851.3862\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 598us/step - loss: 5825.0410 - mae: 5825.0410\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 284us/step - loss: 5794.9907 - mae: 5794.9907\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 589us/step - loss: 5765.9893 - mae: 5765.9893\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 299us/step - loss: 5731.2280 - mae: 5731.2280\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 583us/step - loss: 5703.0244 - mae: 5703.0244\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 299us/step - loss: 5668.1714 - mae: 5668.1714\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 582us/step - loss: 5630.5601 - mae: 5630.5601\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 305us/step - loss: 5593.1592 - mae: 5593.1592\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 589us/step - loss: 5553.4409 - mae: 5553.4409\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 292us/step - loss: 5509.8950 - mae: 5509.8950\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 592us/step - loss: 5471.8491 - mae: 5471.8491\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 295us/step - loss: 5421.2515 - mae: 5421.2515\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 583us/step - loss: 5377.8486 - mae: 5377.8486\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 289us/step - loss: 5328.7554 - mae: 5328.7554\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 592us/step - loss: 5276.2686 - mae: 5276.2686\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 299us/step - loss: 5228.6899 - mae: 5228.6899\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 580us/step - loss: 5173.3467 - mae: 5173.3467\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 297us/step - loss: 5110.1870 - mae: 5110.1870\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 290us/step - loss: 5049.4668 - mae: 5049.4668\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 292us/step - loss: 4992.6577 - mae: 4992.6577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a79d4c70a0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### We will add adam for adding extra layers\n",
    "\n",
    "insurance_model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100), # Added an extra layer\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "## Remember optimizers start with caps\n",
    "insurance_model_4.compile(loss = tf.keras.losses.mae,\n",
    "                       optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                       metrics = [\"mae\"])\n",
    "\n",
    "insurance_model_4.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ready-interpretation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 459us/step - loss: 4903.0669 - mae: 4903.0669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4903.06689453125, 4903.06689453125]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model_4.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "occupational-ballot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9575.4421, 13346.089736364485)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.median(), y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eastern-photograph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Layer dense_57 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 236us/step - loss: 13272.2881 - mae: 13272.2881\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 13072.9277 - mae: 13072.9277\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 12662.5908 - mae: 12662.5908\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 11889.7139 - mae: 11889.7139\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 10662.4092 - mae: 10662.4092\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 9202.4922 - mae: 9202.4922\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7979.2954 - mae: 7979.2954\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 7499.0933 - mae: 7499.0933\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7432.0010 - mae: 7432.0010\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7412.4346 - mae: 7412.4346\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7393.9111 - mae: 7393.9111\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7371.9258 - mae: 7371.9258\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7351.4976 - mae: 7351.4976\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7329.2949 - mae: 7329.2949\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 7310.1724 - mae: 7310.1724\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7287.4629 - mae: 7287.4629\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7267.8647 - mae: 7267.8647\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7244.2969 - mae: 7244.2969\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7222.0854 - mae: 7222.0854\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7198.7871 - mae: 7198.7871\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7179.8550 - mae: 7179.8550\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7152.2739 - mae: 7152.2739\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7127.4922 - mae: 7127.4922\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7102.6724 - mae: 7102.6724\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7084.1357 - mae: 7084.1357\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7052.8872 - mae: 7052.8872\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7024.1108 - mae: 7024.1108\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 6996.0649 - mae: 6996.0649\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6967.6802 - mae: 6967.6802\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6940.9121 - mae: 6940.9121\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6909.5054 - mae: 6909.5054\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6881.6870 - mae: 6881.6870\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6850.0957 - mae: 6850.0957\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6818.5674 - mae: 6818.5674\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 6785.2480 - mae: 6785.2480\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6750.7588 - mae: 6750.7588\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6714.5415 - mae: 6714.5415\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6683.5693 - mae: 6683.5693\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6645.2461 - mae: 6645.2461\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6610.1763 - mae: 6610.1763\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 6576.6758 - mae: 6576.6758\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6549.2754 - mae: 6549.2754\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6519.6152 - mae: 6519.6152\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6496.0508 - mae: 6496.0508\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6482.4355 - mae: 6482.4355\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6465.5088 - mae: 6465.5088\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6446.8140 - mae: 6446.8140\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 6432.7988 - mae: 6432.7988\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6418.8574 - mae: 6418.8574\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6404.8340 - mae: 6404.8340\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6390.6074 - mae: 6390.6074\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6379.0186 - mae: 6379.0186\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6364.5356 - mae: 6364.5356\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 6350.4873 - mae: 6350.4873\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6336.6304 - mae: 6336.6304\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6322.3267 - mae: 6322.3267\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6308.8784 - mae: 6308.8784\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6295.0078 - mae: 6295.0078\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - ETA: 0s - loss: 4873.0425 - mae: 4873.042 - 0s 0s/step - loss: 6278.9526 - mae: 6278.9526\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6268.0845 - mae: 6268.0845\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 6248.1304 - mae: 6248.1304\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6235.2002 - mae: 6235.2002\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6216.3994 - mae: 6216.3994\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6198.9331 - mae: 6198.9331\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6181.4434 - mae: 6181.4434\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6163.5479 - mae: 6163.5479\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 6150.7378 - mae: 6150.7378\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6127.7241 - mae: 6127.7241\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6110.5439 - mae: 6110.5439\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 6089.5190 - mae: 6089.5190\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 6069.2544 - mae: 6069.2544\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 6049.4536 - mae: 6049.4536\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 0s/step - loss: 6033.7764 - mae: 6033.7764\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 6004.7275 - mae: 6004.7275\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 5982.8755 - mae: 5982.8755\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5967.6543 - mae: 5967.6543\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5934.1958 - mae: 5934.1958\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5909.3242 - mae: 5909.3242\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5884.0205 - mae: 5884.0205\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5854.6230 - mae: 5854.6230\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 5827.6245 - mae: 5827.6245\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 5797.6274 - mae: 5797.6274\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5768.1704 - mae: 5768.1704\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5733.8584 - mae: 5733.8584\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5708.0942 - mae: 5708.0942\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5670.6138 - mae: 5670.6138\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 5631.5747 - mae: 5631.5747\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 5594.3262 - mae: 5594.3262\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5553.4062 - mae: 5553.4062\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5509.5708 - mae: 5509.5708\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5470.3296 - mae: 5470.3296\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5419.7197 - mae: 5419.7197\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 5375.5161 - mae: 5375.5161\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 5326.1201 - mae: 5326.1201\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 5271.0283 - mae: 5271.0283\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5221.6621 - mae: 5221.6621\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5165.6968 - mae: 5165.6968\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5099.9487 - mae: 5099.9487\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5037.0234 - mae: 5037.0234\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4976.4092 - mae: 4976.4092\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 4901.8159 - mae: 4901.8159\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 4825.5767 - mae: 4825.5767\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4755.8325 - mae: 4755.8325\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4670.8633 - mae: 4670.8633\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4578.9756 - mae: 4578.9756\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4493.8496 - mae: 4493.8496\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 4407.5122 - mae: 4407.5122\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 4322.8076 - mae: 4322.8076\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4238.4473 - mae: 4238.4473\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4157.2271 - mae: 4157.2271\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4086.1206 - mae: 4086.1206\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4025.2771 - mae: 4025.2771\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3972.5776 - mae: 3972.5776\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3944.9841 - mae: 3944.9841\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3899.9688 - mae: 3899.9688\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3885.0781 - mae: 3885.0781\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3874.3979 - mae: 3874.3979\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3858.4153 - mae: 3858.4153\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3840.5505 - mae: 3840.5505\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3825.3252 - mae: 3825.3252\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3817.2092 - mae: 3817.2092\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3813.2834 - mae: 3813.2834\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3806.6841 - mae: 3806.6841\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3801.7285 - mae: 3801.7285\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3790.4097 - mae: 3790.4097\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3803.2791 - mae: 3803.2791\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3794.3672 - mae: 3794.3672\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3788.5715 - mae: 3788.5715\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3799.3557 - mae: 3799.3557\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3784.4597 - mae: 3784.4597\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3778.3162 - mae: 3778.3162\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3772.2090 - mae: 3772.2090\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3767.7876 - mae: 3767.7876\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3767.4211 - mae: 3767.4211\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3765.1833 - mae: 3765.1833\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3764.2710 - mae: 3764.2710\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3770.7673 - mae: 3770.7673\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3779.6179 - mae: 3779.6179\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3759.5835 - mae: 3759.5835\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3760.9390 - mae: 3760.9390\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3762.4822 - mae: 3762.4822\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3761.2358 - mae: 3761.2358\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3752.1274 - mae: 3752.1274\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3748.6724 - mae: 3748.6724\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3749.4062 - mae: 3749.4062\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3753.4209 - mae: 3753.4209\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3750.8137 - mae: 3750.8137\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3753.5659 - mae: 3753.5659\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3742.3750 - mae: 3742.3750\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3737.4175 - mae: 3737.4175\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3739.8638 - mae: 3739.8638\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 459us/step - loss: 3741.1025 - mae: 3741.1025\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3742.6467 - mae: 3742.6467\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3735.3145 - mae: 3735.3145\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3737.7056 - mae: 3737.7056\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3734.7417 - mae: 3734.7417\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3730.7812 - mae: 3730.7812\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3728.2102 - mae: 3728.2102\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3724.4158 - mae: 3724.4158\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3731.6577 - mae: 3731.6577\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3726.8870 - mae: 3726.8870\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3723.4143 - mae: 3723.4143\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3720.9204 - mae: 3720.9204\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3725.4658 - mae: 3725.4658\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3716.1956 - mae: 3716.1956\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3720.2175 - mae: 3720.2175\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3717.8333 - mae: 3717.8333\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3713.2722 - mae: 3713.2722\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3712.9412 - mae: 3712.9412\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3706.6980 - mae: 3706.6980\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3706.5725 - mae: 3706.5725\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3707.9958 - mae: 3707.9958\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3703.5552 - mae: 3703.5552\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3708.1145 - mae: 3708.1145\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3709.1240 - mae: 3709.1240\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3704.6670 - mae: 3704.6670\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3698.5349 - mae: 3698.5349\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3694.6528 - mae: 3694.6528\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3703.9700 - mae: 3703.9700\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3709.0935 - mae: 3709.0935\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3694.1440 - mae: 3694.1440\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3691.5254 - mae: 3691.5254\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3689.0459 - mae: 3689.0459\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3695.9583 - mae: 3695.9583\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3691.6995 - mae: 3691.6995\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3695.9041 - mae: 3695.9041\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3686.4585 - mae: 3686.4585\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3691.6106 - mae: 3691.6106\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3681.8264 - mae: 3681.8264\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3680.5708 - mae: 3680.5708\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3699.5967 - mae: 3699.5967\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3684.8267 - mae: 3684.8267\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3672.9512 - mae: 3672.9512\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3673.8882 - mae: 3673.8882\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3670.8635 - mae: 3670.8635\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3679.4722 - mae: 3679.4722\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3664.4231 - mae: 3664.4231\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3670.8953 - mae: 3670.8953\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3678.5244 - mae: 3678.5244\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3665.3640 - mae: 3665.3640\n"
     ]
    }
   ],
   "source": [
    "## Now we increase the number of epochs\n",
    "\n",
    "insurance_model_5 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "insurance_model_5.compile(loss= tf.keras.losses.mae,\n",
    "                         optimizer = tf.keras.optimizers.Adam(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "history = insurance_model_5.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "precious-suspension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 0s/step - loss: 3663.2419 - mae: 3663.2419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3663.241943359375, 3663.241943359375]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model_5.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "applicable-lodge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 0s/step - loss: 3488.1292 - mae: 3488.1292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3488.129150390625, 3488.129150390625]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model_5.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "clean-sugar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-species",
   "metadata": {},
   "source": [
    "##### Tensorflow early stopping callback, which is a tensorflow component that stops training once model stops improving.\n",
    "##### https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
    "##### https://keras.io/api/callbacks/early_stopping/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "statewide-reward",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Layer dense_66 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 530us/step - loss: 13302.8496 - mae: 13302.8496\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 13137.6465 - mae: 13137.6465\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 12801.3154 - mae: 12801.3154\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 12138.6543 - mae: 12138.6543\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 11018.4424 - mae: 11018.4424\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 9571.0615 - mae: 9571.0615\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 8228.6885 - mae: 8228.6885\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 7558.5996 - mae: 7558.5996\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7441.6670 - mae: 7441.6670\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7420.4492 - mae: 7420.4492\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7401.8594 - mae: 7401.8594\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7379.8662 - mae: 7379.8662\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7359.4741 - mae: 7359.4741\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7337.2983 - mae: 7337.2983\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 7318.2783 - mae: 7318.2783\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7295.6748 - mae: 7295.6748\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7276.0293 - mae: 7276.0293\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7252.0029 - mae: 7252.0029\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7229.8481 - mae: 7229.8481\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7206.5615 - mae: 7206.5615\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 7187.0288 - mae: 7187.0288\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7159.4653 - mae: 7159.4653\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - ETA: 0s - loss: 4609.3115 - mae: 4609.311 - 0s 0s/step - loss: 7134.3076 - mae: 7134.3076\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7109.2056 - mae: 7109.2056\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7089.6982 - mae: 7089.6982\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7058.5073 - mae: 7058.5073\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7028.5942 - mae: 7028.5942\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 6999.6050 - mae: 6999.6050\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6970.5396 - mae: 6970.5396\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6942.0371 - mae: 6942.0371\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6909.8062 - mae: 6909.8062\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6880.4185 - mae: 6880.4185\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6847.1953 - mae: 6847.1953\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6814.3501 - mae: 6814.3501\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 6778.9336 - mae: 6778.9336\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6742.8569 - mae: 6742.8569\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6705.5640 - mae: 6705.5640\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6672.5205 - mae: 6672.5205\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6633.5967 - mae: 6633.5967\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6597.1919 - mae: 6597.1919\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 6565.3857 - mae: 6565.3857\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6540.6577 - mae: 6540.6577\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6511.4082 - mae: 6511.4082\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6489.3940 - mae: 6489.3940\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6478.3335 - mae: 6478.3335\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6460.6641 - mae: 6460.6641\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 6444.1865 - mae: 6444.1865\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 6430.2207 - mae: 6430.2207\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6417.3481 - mae: 6417.3481\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6403.2319 - mae: 6403.2319\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6390.3618 - mae: 6390.3618\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6377.7026 - mae: 6377.7026\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6363.6187 - mae: 6363.6187\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6349.2334 - mae: 6349.2334\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 6335.4165 - mae: 6335.4165\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 6321.3403 - mae: 6321.3403\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 6308.0049 - mae: 6308.0049\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 6294.0869 - mae: 6294.0869\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6277.9336 - mae: 6277.9336\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6267.1025 - mae: 6267.1025\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 6247.2427 - mae: 6247.2427\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6234.8848 - mae: 6234.8848\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6216.5137 - mae: 6216.5137\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6199.1611 - mae: 6199.1611\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6181.5596 - mae: 6181.5596\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6163.7544 - mae: 6163.7544\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6150.7881 - mae: 6150.7881\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 6127.6436 - mae: 6127.6436\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 6110.9292 - mae: 6110.9292\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 6090.0864 - mae: 6090.0864\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 6070.4653 - mae: 6070.4653\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6049.9067 - mae: 6049.9067\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 459us/step - loss: 6036.3970 - mae: 6036.3970\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 6006.6050 - mae: 6006.6050\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 5984.5986 - mae: 5984.5986\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5969.8970 - mae: 5969.8970\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5937.5210 - mae: 5937.5210\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5913.1470 - mae: 5913.1470\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5888.2505 - mae: 5888.2505\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5859.0576 - mae: 5859.0576\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 5832.7612 - mae: 5832.7612\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 5803.1670 - mae: 5803.1670\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 5774.9365 - mae: 5774.9365\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 5739.9922 - mae: 5739.9922\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 5713.3154 - mae: 5713.3154\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5679.5161 - mae: 5679.5161\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 5641.5381 - mae: 5641.5381\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 5604.9663 - mae: 5604.9663\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5565.9604 - mae: 5565.9604\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5522.7554 - mae: 5522.7554\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5486.1025 - mae: 5486.1025\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5436.1714 - mae: 5436.1714\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5392.9624 - mae: 5392.9624\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 5344.6128 - mae: 5344.6128\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 5293.6724 - mae: 5293.6724\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5246.1973 - mae: 5246.1973\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5192.0381 - mae: 5192.0381\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5129.8003 - mae: 5129.8003\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5070.4907 - mae: 5070.4907\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 5014.5073 - mae: 5014.5073\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 4943.6909 - mae: 4943.6909\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4870.8530 - mae: 4870.8530\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4804.8223 - mae: 4804.8223\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4725.4585 - mae: 4725.4585\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4640.3447 - mae: 4640.3447\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4557.9351 - mae: 4557.9351\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 4473.4683 - mae: 4473.4683\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 4389.0215 - mae: 4389.0215\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4307.0156 - mae: 4307.0156\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4226.9795 - mae: 4226.9795\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4151.5806 - mae: 4151.5806\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4083.9202 - mae: 4083.9202\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 4023.4622 - mae: 4023.4622\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3981.9631 - mae: 3981.9631\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3942.5925 - mae: 3942.5925\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3916.4211 - mae: 3916.4211\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3897.3794 - mae: 3897.3794\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3871.1006 - mae: 3871.1006\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3853.7070 - mae: 3853.7070\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3837.3276 - mae: 3837.3276\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3830.7903 - mae: 3830.7903\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3823.7532 - mae: 3823.7532\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3818.4663 - mae: 3818.4663\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3808.9187 - mae: 3808.9187\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3798.7915 - mae: 3798.7915\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3809.5039 - mae: 3809.5039\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3800.4443 - mae: 3800.4443\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3793.1787 - mae: 3793.1787\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3803.7258 - mae: 3803.7258\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3790.7510 - mae: 3790.7510\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3783.9954 - mae: 3783.9954\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3777.2581 - mae: 3777.2581\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3773.4976 - mae: 3773.4976\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3772.7529 - mae: 3772.7529\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3769.4958 - mae: 3769.4958\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3768.1213 - mae: 3768.1213\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3776.5779 - mae: 3776.5779\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3783.7700 - mae: 3783.7700\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3763.9829 - mae: 3763.9829\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3765.2466 - mae: 3765.2466\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3765.1633 - mae: 3765.1633\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3767.9028 - mae: 3767.9028\n"
     ]
    }
   ],
   "source": [
    "## patience means number of epochs with no improvements and monitor: Quantity to be monitored.\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "insurance_model_6 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "insurance_model_6.compile(loss= tf.keras.losses.mae,\n",
    "                         optimizer = tf.keras.optimizers.Adam(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "history_2 = insurance_model_6.fit(X_train, y_train, epochs=200,callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "sorted-sherman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model ran til 142 epochs and stopped automatically as there was no improvement\n",
    "pd.DataFrame(history_2.history).plot()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-thing",
   "metadata": {},
   "source": [
    "## Preprocessing Data. Normalization and Standardisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "communist-victory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X['age'].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "polyphonic-usage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X['bmi'].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "rolled-inclusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X['children'].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "breeding-mounting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    574\n",
       "1    324\n",
       "2    240\n",
       "3    157\n",
       "4     25\n",
       "5     18\n",
       "Name: children, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['children'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "american-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = pd.read_csv(\"insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "thousand-fishing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-plane",
   "metadata": {},
   "source": [
    "### import proper sklearn classes for standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "explicit-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cleared-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(),['age','bmi','children']), #turn all values in this column between 0 and 1\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"),[\"smoker\",\"sex\",\"region\"]) #ignore columns that one hot encoder doesnt know\n",
    ")\n",
    "\n",
    "#Create our X and y values\n",
    "X = insurance.drop(\"charges\", axis=1)\n",
    "y = insurance[\"charges\"]\n",
    "\n",
    "#Build our train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 42)\n",
    "\n",
    "#Fit the column transformer to our training data\n",
    "ct.fit(X_train)\n",
    "#Transform training and test data with normalization(MinMaxScaler) and OneHot Encoder\n",
    "\n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "surprised-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### What our data looked like before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "stuck-steam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                18\n",
       "sex              male\n",
       "bmi             33.77\n",
       "children            1\n",
       "smoker             no\n",
       "region      southeast\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### What does our data looks like now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "alpha-puzzle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal[0] #here you cannot access like X_train.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "lonely-capitol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60869565, 0.10734463, 0.4       , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.63043478, 0.22491256, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.73913043, 0.23944041, 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.86956522, 0.24791499, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.41304348, 0.85122411, 0.4       , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.80434783, 0.37503363, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "meaningful-complaint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 6), (1070, 11))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "essential-galaxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "34/34 [==============================] - 0s 531us/step - loss: 13342.8506 - mae: 13342.8506\n",
      "Epoch 2/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 13333.7686 - mae: 13333.7686\n",
      "Epoch 3/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 13312.5342 - mae: 13312.5342\n",
      "Epoch 4/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 13268.8975 - mae: 13268.8975\n",
      "Epoch 5/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 13191.5244 - mae: 13191.5244\n",
      "Epoch 6/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 13069.2363 - mae: 13069.2363\n",
      "Epoch 7/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 12891.7236 - mae: 12891.7236\n",
      "Epoch 8/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 12648.8340 - mae: 12648.8340\n",
      "Epoch 9/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 12330.3096 - mae: 12330.3096\n",
      "Epoch 10/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 11931.1182 - mae: 11931.1182\n",
      "Epoch 11/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 11459.6943 - mae: 11459.6943\n",
      "Epoch 12/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 10955.2119 - mae: 10955.2119\n",
      "Epoch 13/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 10454.4570 - mae: 10454.4570\n",
      "Epoch 14/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 9956.7090 - mae: 9956.7090\n",
      "Epoch 15/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 9485.8457 - mae: 9485.8457\n",
      "Epoch 16/500\n",
      "34/34 [==============================] - ETA: 0s - loss: 12204.3232 - mae: 12204.323 - 0s 0s/step - loss: 9068.2432 - mae: 9068.2432\n",
      "Epoch 17/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 8723.3184 - mae: 8723.3184\n",
      "Epoch 18/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 8442.8955 - mae: 8442.8955\n",
      "Epoch 19/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 8227.9463 - mae: 8227.9463\n",
      "Epoch 20/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 8082.2505 - mae: 8082.2505\n",
      "Epoch 21/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 7973.9834 - mae: 7973.9834\n",
      "Epoch 22/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7898.7344 - mae: 7898.7344\n",
      "Epoch 23/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7839.7954 - mae: 7839.7954\n",
      "Epoch 24/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7787.1704 - mae: 7787.1704\n",
      "Epoch 25/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7748.4946 - mae: 7748.4946\n",
      "Epoch 26/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7696.9551 - mae: 7696.9551\n",
      "Epoch 27/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7655.1250 - mae: 7655.1250\n",
      "Epoch 28/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7612.6890 - mae: 7612.6890\n",
      "Epoch 29/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7570.3120 - mae: 7570.3120\n",
      "Epoch 30/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7526.8076 - mae: 7526.8076\n",
      "Epoch 31/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7482.9077 - mae: 7482.9077\n",
      "Epoch 32/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 7438.7593 - mae: 7438.7593\n",
      "Epoch 33/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7394.3716 - mae: 7394.3716\n",
      "Epoch 34/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 7346.0811 - mae: 7346.0811\n",
      "Epoch 35/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7299.2554 - mae: 7299.2554\n",
      "Epoch 36/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7248.9922 - mae: 7248.9922\n",
      "Epoch 37/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7198.6064 - mae: 7198.6064\n",
      "Epoch 38/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7147.4873 - mae: 7147.4873\n",
      "Epoch 39/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7092.6133 - mae: 7092.6133\n",
      "Epoch 40/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7037.0537 - mae: 7037.0537\n",
      "Epoch 41/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 6980.5537 - mae: 6980.5537\n",
      "Epoch 42/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6921.6001 - mae: 6921.6001\n",
      "Epoch 43/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6858.9473 - mae: 6858.9473\n",
      "Epoch 44/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6792.5679 - mae: 6792.5679\n",
      "Epoch 45/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 6725.2554 - mae: 6725.2554\n",
      "Epoch 46/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 6656.0366 - mae: 6656.0366\n",
      "Epoch 47/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 6584.8472 - mae: 6584.8472\n",
      "Epoch 48/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6505.8105 - mae: 6505.8105\n",
      "Epoch 49/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6426.7798 - mae: 6426.7798\n",
      "Epoch 50/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6340.8076 - mae: 6340.8076\n",
      "Epoch 51/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6256.0825 - mae: 6256.0825\n",
      "Epoch 52/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6163.2725 - mae: 6163.2725\n",
      "Epoch 53/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 6067.4248 - mae: 6067.4248\n",
      "Epoch 54/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 5968.7964 - mae: 5968.7964\n",
      "Epoch 55/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5861.3535 - mae: 5861.3535\n",
      "Epoch 56/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5752.9209 - mae: 5752.9209\n",
      "Epoch 57/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5637.5327 - mae: 5637.5327\n",
      "Epoch 58/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5520.0259 - mae: 5520.0259\n",
      "Epoch 59/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5401.5576 - mae: 5401.5576\n",
      "Epoch 60/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 5277.6548 - mae: 5277.6548\n",
      "Epoch 61/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 5150.4277 - mae: 5150.4277\n",
      "Epoch 62/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 5020.0000 - mae: 5020.0000\n",
      "Epoch 63/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4890.6875 - mae: 4890.6875\n",
      "Epoch 64/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4758.4292 - mae: 4758.4292\n",
      "Epoch 65/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4632.1870 - mae: 4632.1870\n",
      "Epoch 66/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 4507.3813 - mae: 4507.3813\n",
      "Epoch 67/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 4397.6069 - mae: 4397.6069\n",
      "Epoch 68/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4290.2671 - mae: 4290.2671\n",
      "Epoch 69/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4188.4419 - mae: 4188.4419\n",
      "Epoch 70/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4095.2202 - mae: 4095.2202\n",
      "Epoch 71/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4009.0481 - mae: 4009.0481\n",
      "Epoch 72/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3934.5276 - mae: 3934.5276\n",
      "Epoch 73/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3871.4812 - mae: 3871.4812\n",
      "Epoch 74/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3818.4783 - mae: 3818.4783\n",
      "Epoch 75/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3776.8767 - mae: 3776.8767\n",
      "Epoch 76/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3746.3123 - mae: 3746.3123\n",
      "Epoch 77/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3721.4446 - mae: 3721.4446\n",
      "Epoch 78/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3704.0859 - mae: 3704.0859\n",
      "Epoch 79/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3692.2102 - mae: 3692.2102\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 460us/step - loss: 3682.9065 - mae: 3682.9065\n",
      "Epoch 81/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3676.7500 - mae: 3676.7500\n",
      "Epoch 82/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3673.4827 - mae: 3673.4827\n",
      "Epoch 83/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3667.5503 - mae: 3667.5503\n",
      "Epoch 84/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3664.4333 - mae: 3664.4333\n",
      "Epoch 85/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3661.6331 - mae: 3661.6331\n",
      "Epoch 86/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3660.1865 - mae: 3660.1865\n",
      "Epoch 87/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3657.1775 - mae: 3657.1775\n",
      "Epoch 88/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3654.7153 - mae: 3654.7153\n",
      "Epoch 89/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3653.2825 - mae: 3653.2825\n",
      "Epoch 90/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3651.6047 - mae: 3651.6047\n",
      "Epoch 91/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3648.4160 - mae: 3648.4160\n",
      "Epoch 92/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3647.8708 - mae: 3647.8708\n",
      "Epoch 93/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3645.7322 - mae: 3645.7322\n",
      "Epoch 94/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3643.9026 - mae: 3643.9026\n",
      "Epoch 95/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3644.9529 - mae: 3644.9529\n",
      "Epoch 96/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3642.0464 - mae: 3642.0464\n",
      "Epoch 97/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3639.4062 - mae: 3639.4062\n",
      "Epoch 98/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3637.3513 - mae: 3637.3513\n",
      "Epoch 99/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3636.9199 - mae: 3636.9199\n",
      "Epoch 100/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3635.4622 - mae: 3635.4622\n",
      "Epoch 101/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3632.4321 - mae: 3632.4321\n",
      "Epoch 102/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3630.0193 - mae: 3630.0193\n",
      "Epoch 103/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3628.7903 - mae: 3628.7903\n",
      "Epoch 104/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3626.4297 - mae: 3626.4297\n",
      "Epoch 105/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3624.7976 - mae: 3624.7976\n",
      "Epoch 106/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3623.4875 - mae: 3623.4875\n",
      "Epoch 107/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3622.9939 - mae: 3622.9939\n",
      "Epoch 108/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3620.2371 - mae: 3620.2371\n",
      "Epoch 109/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3620.7659 - mae: 3620.7659\n",
      "Epoch 110/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3617.6436 - mae: 3617.6436\n",
      "Epoch 111/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3614.6909 - mae: 3614.6909\n",
      "Epoch 112/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3612.6252 - mae: 3612.6252\n",
      "Epoch 113/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3611.1250 - mae: 3611.1250\n",
      "Epoch 114/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3610.2146 - mae: 3610.2146\n",
      "Epoch 115/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3608.4810 - mae: 3608.4810\n",
      "Epoch 116/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3606.9719 - mae: 3606.9719\n",
      "Epoch 117/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3603.9993 - mae: 3603.9993\n",
      "Epoch 118/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3600.5583 - mae: 3600.5583\n",
      "Epoch 119/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3602.5566 - mae: 3602.5566\n",
      "Epoch 120/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3599.6277 - mae: 3599.6277\n",
      "Epoch 121/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3594.6169 - mae: 3594.6169\n",
      "Epoch 122/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3593.8860 - mae: 3593.8860\n",
      "Epoch 123/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3591.8752 - mae: 3591.8752\n",
      "Epoch 124/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3589.6396 - mae: 3589.6396\n",
      "Epoch 125/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3587.6592 - mae: 3587.6592\n",
      "Epoch 126/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3586.6021 - mae: 3586.6021\n",
      "Epoch 127/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3587.1802 - mae: 3587.1802\n",
      "Epoch 128/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3583.3687 - mae: 3583.3687\n",
      "Epoch 129/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3582.0444 - mae: 3582.0444\n",
      "Epoch 130/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3578.4500 - mae: 3578.4500\n",
      "Epoch 131/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3577.0615 - mae: 3577.0615\n",
      "Epoch 132/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3574.2039 - mae: 3574.2039\n",
      "Epoch 133/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3572.5942 - mae: 3572.5942\n",
      "Epoch 134/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3570.5137 - mae: 3570.5137\n",
      "Epoch 135/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3568.6575 - mae: 3568.6575\n",
      "Epoch 136/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3567.3132 - mae: 3567.3132\n",
      "Epoch 137/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3565.4375 - mae: 3565.4375\n",
      "Epoch 138/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3563.2744 - mae: 3563.2744\n",
      "Epoch 139/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3562.5100 - mae: 3562.5100\n",
      "Epoch 140/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3560.4216 - mae: 3560.4216\n",
      "Epoch 141/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3560.4685 - mae: 3560.4685\n",
      "Epoch 142/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3557.3650 - mae: 3557.3650\n",
      "Epoch 143/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3557.4775 - mae: 3557.4775\n",
      "Epoch 144/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3554.4041 - mae: 3554.4041\n",
      "Epoch 145/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3552.6101 - mae: 3552.6101\n",
      "Epoch 146/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3552.7764 - mae: 3552.7764\n",
      "Epoch 147/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3550.3921 - mae: 3550.3921\n",
      "Epoch 148/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3549.1006 - mae: 3549.1006\n",
      "Epoch 149/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3546.2546 - mae: 3546.2546\n",
      "Epoch 150/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3546.0637 - mae: 3546.0637\n",
      "Epoch 151/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3544.3418 - mae: 3544.3418\n",
      "Epoch 152/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3542.6804 - mae: 3542.6804\n",
      "Epoch 153/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3541.1755 - mae: 3541.1755\n",
      "Epoch 154/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3542.4973 - mae: 3542.4973\n",
      "Epoch 155/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3540.1350 - mae: 3540.1350\n",
      "Epoch 156/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3538.3142 - mae: 3538.3142\n",
      "Epoch 157/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3536.9683 - mae: 3536.9683\n",
      "Epoch 158/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3533.7793 - mae: 3533.7793\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 460us/step - loss: 3532.3057 - mae: 3532.3057\n",
      "Epoch 160/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3532.0557 - mae: 3532.0557\n",
      "Epoch 161/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3529.0830 - mae: 3529.0830\n",
      "Epoch 162/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3528.3975 - mae: 3528.3975\n",
      "Epoch 163/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3526.4636 - mae: 3526.4636\n",
      "Epoch 164/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3525.9783 - mae: 3525.9783\n",
      "Epoch 165/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3523.8193 - mae: 3523.8193\n",
      "Epoch 166/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3522.0894 - mae: 3522.0894\n",
      "Epoch 167/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3521.1821 - mae: 3521.1821\n",
      "Epoch 168/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3520.1299 - mae: 3520.1299\n",
      "Epoch 169/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3518.8704 - mae: 3518.8704\n",
      "Epoch 170/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3517.5066 - mae: 3517.5066\n",
      "Epoch 171/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3517.2417 - mae: 3517.2417\n",
      "Epoch 172/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3515.4907 - mae: 3515.4907\n",
      "Epoch 173/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3514.1689 - mae: 3514.1689\n",
      "Epoch 174/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3513.1550 - mae: 3513.1550\n",
      "Epoch 175/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3511.6833 - mae: 3511.6833\n",
      "Epoch 176/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3511.6968 - mae: 3511.6968\n",
      "Epoch 177/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3512.0864 - mae: 3512.0864\n",
      "Epoch 178/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3509.5417 - mae: 3509.5417\n",
      "Epoch 179/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3511.4817 - mae: 3511.4817\n",
      "Epoch 180/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3506.5205 - mae: 3506.5205\n",
      "Epoch 181/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3504.4158 - mae: 3504.4158\n",
      "Epoch 182/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3503.8242 - mae: 3503.8242\n",
      "Epoch 183/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3501.9446 - mae: 3501.9446\n",
      "Epoch 184/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3501.2690 - mae: 3501.2690\n",
      "Epoch 185/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3500.9094 - mae: 3500.9094\n",
      "Epoch 186/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3498.2861 - mae: 3498.2861\n",
      "Epoch 187/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3498.7942 - mae: 3498.7942\n",
      "Epoch 188/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3495.8193 - mae: 3495.8193\n",
      "Epoch 189/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3494.4324 - mae: 3494.4324\n",
      "Epoch 190/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3495.8582 - mae: 3495.8582\n",
      "Epoch 191/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3501.8132 - mae: 3501.8132\n",
      "Epoch 192/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3491.2107 - mae: 3491.2107\n",
      "Epoch 193/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3490.9866 - mae: 3490.9866\n",
      "Epoch 194/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3488.1865 - mae: 3488.1865\n",
      "Epoch 195/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3487.4800 - mae: 3487.4800\n",
      "Epoch 196/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3488.5747 - mae: 3488.5747\n",
      "Epoch 197/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3485.3999 - mae: 3485.3999\n",
      "Epoch 198/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3484.0017 - mae: 3484.0017\n",
      "Epoch 199/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3482.9111 - mae: 3482.9111\n",
      "Epoch 200/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3483.4421 - mae: 3483.4421\n",
      "Epoch 201/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3479.6172 - mae: 3479.6172\n",
      "Epoch 202/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3479.1990 - mae: 3479.1990\n",
      "Epoch 203/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3476.6575 - mae: 3476.6575\n",
      "Epoch 204/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3477.2656 - mae: 3477.2656\n",
      "Epoch 205/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3475.2642 - mae: 3475.2642\n",
      "Epoch 206/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3474.4995 - mae: 3474.4995\n",
      "Epoch 207/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3475.0789 - mae: 3475.0789\n",
      "Epoch 208/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3474.1030 - mae: 3474.1030\n",
      "Epoch 209/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.7031 - mae: 3473.7031\n",
      "Epoch 210/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.4019 - mae: 3473.4019\n",
      "Epoch 211/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.8010 - mae: 3472.8010\n",
      "Epoch 212/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3473.0205 - mae: 3473.0205\n",
      "Epoch 213/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.4758 - mae: 3472.4758\n",
      "Epoch 214/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3474.5479 - mae: 3474.5479\n",
      "Epoch 215/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3473.4429 - mae: 3473.4429\n",
      "Epoch 216/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.5784 - mae: 3472.5784\n",
      "Epoch 217/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3474.8987 - mae: 3474.8987\n",
      "Epoch 218/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3472.3069 - mae: 3472.3069\n",
      "Epoch 219/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.7195 - mae: 3472.7195\n",
      "Epoch 220/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.7715 - mae: 3471.7715\n",
      "Epoch 221/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3474.2168 - mae: 3474.2168\n",
      "Epoch 222/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.8162 - mae: 3473.8162\n",
      "Epoch 223/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.6270 - mae: 3472.6270\n",
      "Epoch 224/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3473.0852 - mae: 3473.0852\n",
      "Epoch 225/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3473.0120 - mae: 3473.0120\n",
      "Epoch 226/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3471.8013 - mae: 3471.8013\n",
      "Epoch 227/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.3611 - mae: 3471.3611\n",
      "Epoch 228/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.5083 - mae: 3473.5083\n",
      "Epoch 229/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.1272 - mae: 3472.1272\n",
      "Epoch 230/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3474.1084 - mae: 3474.1084\n",
      "Epoch 231/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3471.8494 - mae: 3471.8494\n",
      "Epoch 232/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.7971 - mae: 3472.7971\n",
      "Epoch 233/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.9595 - mae: 3471.9595\n",
      "Epoch 234/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.3762 - mae: 3472.3762\n",
      "Epoch 235/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3474.5295 - mae: 3474.5295\n",
      "Epoch 236/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.5276 - mae: 3473.5276\n",
      "Epoch 237/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3472.8840 - mae: 3472.8840\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 460us/step - loss: 3473.1526 - mae: 3473.1526\n",
      "Epoch 239/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3475.0596 - mae: 3475.0596\n",
      "Epoch 240/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.5417 - mae: 3472.5417\n",
      "Epoch 241/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.6929 - mae: 3471.6929\n",
      "Epoch 242/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.8628 - mae: 3473.8628\n",
      "Epoch 243/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3472.3508 - mae: 3472.3508\n",
      "Epoch 244/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3473.7095 - mae: 3473.7095\n",
      "Epoch 245/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.0029 - mae: 3472.0029\n",
      "Epoch 246/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.5842 - mae: 3473.5842\n",
      "Epoch 247/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.4033 - mae: 3472.4033\n",
      "Epoch 248/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3474.0635 - mae: 3474.0635\n",
      "Epoch 249/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3474.6626 - mae: 3474.6626\n",
      "Epoch 250/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3472.4038 - mae: 3472.4038\n",
      "Epoch 251/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3471.3284 - mae: 3471.3284\n",
      "Epoch 252/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.3682 - mae: 3473.3682\n",
      "Epoch 253/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.8125 - mae: 3472.8125\n",
      "Epoch 254/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.6965 - mae: 3471.6965\n",
      "Epoch 255/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.6548 - mae: 3472.6548\n",
      "Epoch 256/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3475.3459 - mae: 3475.3459\n",
      "Epoch 257/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3475.5808 - mae: 3475.5808\n",
      "Epoch 258/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.2263 - mae: 3472.2263\n",
      "Epoch 259/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3474.0728 - mae: 3474.0728\n",
      "Epoch 260/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.9756 - mae: 3471.9756\n",
      "Epoch 261/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.9539 - mae: 3472.9539\n",
      "Epoch 262/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.6846 - mae: 3472.6846\n",
      "Epoch 263/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3472.1826 - mae: 3472.1826\n",
      "Epoch 264/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3472.5896 - mae: 3472.5896\n",
      "Epoch 265/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.8352 - mae: 3472.8352\n",
      "Epoch 266/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.4011 - mae: 3472.4011\n",
      "Epoch 267/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.9167 - mae: 3473.9167\n",
      "Epoch 268/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.9365 - mae: 3471.9365\n",
      "Epoch 269/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3471.7700 - mae: 3471.7700\n",
      "Epoch 270/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3471.9355 - mae: 3471.9355\n",
      "Epoch 271/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.2546 - mae: 3472.2546\n",
      "Epoch 272/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.1157 - mae: 3472.1157\n",
      "Epoch 273/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.6057 - mae: 3472.6057\n",
      "Epoch 274/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.5764 - mae: 3472.5764\n",
      "Epoch 275/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3474.2991 - mae: 3474.2991\n",
      "Epoch 276/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3473.2124 - mae: 3473.2124\n",
      "Epoch 277/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3471.8206 - mae: 3471.8206\n",
      "Epoch 278/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.1985 - mae: 3472.1985\n",
      "Epoch 279/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3475.7332 - mae: 3475.7332\n",
      "Epoch 280/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.9934 - mae: 3471.9934\n",
      "Epoch 281/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.5366 - mae: 3472.5366\n",
      "Epoch 282/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.6179 - mae: 3471.6179\n",
      "Epoch 283/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.9399 - mae: 3472.9399\n",
      "Epoch 284/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.4028 - mae: 3472.4028\n",
      "Epoch 285/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3471.6860 - mae: 3471.6860\n",
      "Epoch 286/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.3259 - mae: 3472.3259\n",
      "Epoch 287/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.6199 - mae: 3472.6199\n",
      "Epoch 288/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.2849 - mae: 3472.2849\n",
      "Epoch 289/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3473.9297 - mae: 3473.9297\n",
      "Epoch 290/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3473.1396 - mae: 3473.1396\n",
      "Epoch 291/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.3015 - mae: 3471.3015\n",
      "Epoch 292/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.8157 - mae: 3473.8157\n",
      "Epoch 293/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.8123 - mae: 3471.8123\n",
      "Epoch 294/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.2996 - mae: 3473.2996\n",
      "Epoch 295/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.2634 - mae: 3473.2634\n",
      "Epoch 296/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3474.0818 - mae: 3474.0818\n",
      "Epoch 297/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3476.4084 - mae: 3476.4084\n",
      "Epoch 298/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3474.9446 - mae: 3474.9446\n",
      "Epoch 299/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.8809 - mae: 3471.8809\n",
      "Epoch 300/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.7610 - mae: 3472.7610\n",
      "Epoch 301/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.2415 - mae: 3472.2415\n",
      "Epoch 302/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3473.7969 - mae: 3473.7969\n",
      "Epoch 303/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3472.8352 - mae: 3472.8352\n",
      "Epoch 304/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.0718 - mae: 3472.0718\n",
      "Epoch 305/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.4321 - mae: 3473.4321\n",
      "Epoch 306/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.2839 - mae: 3472.2839\n",
      "Epoch 307/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.1555 - mae: 3473.1555\n",
      "Epoch 308/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.7805 - mae: 3472.7805\n",
      "Epoch 309/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3474.8743 - mae: 3474.8743\n",
      "Epoch 310/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3473.2434 - mae: 3473.2434\n",
      "Epoch 311/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.4048 - mae: 3472.4048\n",
      "Epoch 312/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.4089 - mae: 3472.4089\n",
      "Epoch 313/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.2759 - mae: 3472.2759\n",
      "Epoch 314/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.7246 - mae: 3471.7246\n",
      "Epoch 315/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3472.9072 - mae: 3472.9072\n",
      "Epoch 316/500\n",
      "34/34 [==============================] - ETA: 0s - loss: 5107.7368 - mae: 5107.736 - 0s 0s/step - loss: 3472.4104 - mae: 3472.4104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.3406 - mae: 3473.3406\n",
      "Epoch 318/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3473.3069 - mae: 3473.3069\n",
      "Epoch 319/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.8479 - mae: 3472.8479\n",
      "Epoch 320/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3471.7134 - mae: 3471.7134\n",
      "Epoch 321/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.5842 - mae: 3472.5842\n",
      "Epoch 322/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3473.4214 - mae: 3473.4214\n",
      "Epoch 323/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3472.1458 - mae: 3472.1458\n",
      "Epoch 324/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.1655 - mae: 3472.1655\n",
      "Epoch 325/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.5264 - mae: 3472.5264\n",
      "Epoch 326/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.0344 - mae: 3473.0344\n",
      "Epoch 327/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3475.1655 - mae: 3475.1655\n",
      "Epoch 328/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3472.8687 - mae: 3472.8687\n",
      "Epoch 329/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3472.6582 - mae: 3472.6582\n",
      "Epoch 330/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.3096 - mae: 3473.3096\n",
      "Epoch 331/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.0676 - mae: 3471.0676\n",
      "Epoch 332/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.8999 - mae: 3472.8999\n",
      "Epoch 333/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.1521 - mae: 3473.1521\n",
      "Epoch 334/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.1924 - mae: 3472.1924\n",
      "Epoch 335/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3474.8669 - mae: 3474.8669\n",
      "Epoch 336/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3472.8262 - mae: 3472.8262\n",
      "Epoch 337/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3470.8257 - mae: 3470.8257\n",
      "Epoch 338/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.0193 - mae: 3473.0193\n",
      "Epoch 339/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.3914 - mae: 3472.3914\n",
      "Epoch 340/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.8994 - mae: 3472.8994\n",
      "Epoch 341/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3472.4624 - mae: 3472.4624\n",
      "Epoch 342/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3472.4170 - mae: 3472.4170\n",
      "Epoch 343/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.7480 - mae: 3471.7480\n",
      "Epoch 344/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.9309 - mae: 3472.9307\n",
      "Epoch 345/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.2732 - mae: 3472.2732\n",
      "Epoch 346/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3475.6155 - mae: 3475.6155\n",
      "Epoch 347/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.3735 - mae: 3472.3735\n",
      "Epoch 348/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3472.5146 - mae: 3472.5146\n",
      "Epoch 349/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3472.8003 - mae: 3472.8003\n",
      "Epoch 350/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3475.0659 - mae: 3475.0659\n",
      "Epoch 351/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.0671 - mae: 3473.0671\n",
      "Epoch 352/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.0076 - mae: 3472.0076\n",
      "Epoch 353/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.3105 - mae: 3472.3105\n",
      "Epoch 354/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3472.7249 - mae: 3472.7249\n",
      "Epoch 355/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3472.2786 - mae: 3472.2786\n",
      "Epoch 356/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.9150 - mae: 3472.9150\n",
      "Epoch 357/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.8899 - mae: 3472.8899\n",
      "Epoch 358/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3477.7854 - mae: 3477.7854\n",
      "Epoch 359/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.1304 - mae: 3473.1304\n",
      "Epoch 360/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.0234 - mae: 3472.0234\n",
      "Epoch 361/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3473.2351 - mae: 3473.2351\n",
      "Epoch 362/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3472.5879 - mae: 3472.5879\n",
      "Epoch 363/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.6201 - mae: 3472.6201\n",
      "Epoch 364/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.9211 - mae: 3471.9211\n",
      "Epoch 365/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.0762 - mae: 3472.0762\n",
      "Epoch 366/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.8855 - mae: 3472.8855\n",
      "Epoch 367/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3471.6187 - mae: 3471.6187\n",
      "Epoch 368/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3474.6616 - mae: 3474.6616\n",
      "Epoch 369/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3473.2927 - mae: 3473.2927\n",
      "Epoch 370/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.0474 - mae: 3472.0474\n",
      "Epoch 371/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.4607 - mae: 3472.4607\n",
      "Epoch 372/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.3577 - mae: 3472.3577\n",
      "Epoch 373/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3476.6069 - mae: 3476.6069\n",
      "Epoch 374/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3473.8013 - mae: 3473.8013\n",
      "Epoch 375/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3472.2817 - mae: 3472.2817\n",
      "Epoch 376/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.9255 - mae: 3472.9255\n",
      "Epoch 377/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.2900 - mae: 3472.2900\n",
      "Epoch 378/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.8286 - mae: 3471.8286\n",
      "Epoch 379/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3474.2878 - mae: 3474.2878\n",
      "Epoch 380/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3472.6470 - mae: 3472.6470\n",
      "Epoch 381/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3473.1262 - mae: 3473.1262\n",
      "Epoch 382/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.0425 - mae: 3472.0425\n",
      "Epoch 383/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.7771 - mae: 3472.7771\n",
      "Epoch 384/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.7805 - mae: 3472.7805\n",
      "Epoch 385/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3474.4561 - mae: 3474.4561\n",
      "Epoch 386/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.6035 - mae: 3472.6035\n",
      "Epoch 387/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3472.0869 - mae: 3472.0869\n",
      "Epoch 388/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3473.0083 - mae: 3473.0083\n",
      "Epoch 389/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.2075 - mae: 3473.2075\n",
      "Epoch 390/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.9199 - mae: 3473.9199\n",
      "Epoch 391/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.2908 - mae: 3473.2908\n",
      "Epoch 392/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3475.2363 - mae: 3475.2363\n",
      "Epoch 393/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3473.9741 - mae: 3473.9741\n",
      "Epoch 394/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3471.8022 - mae: 3471.8022\n",
      "Epoch 395/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3473.5784 - mae: 3473.5784\n",
      "Epoch 396/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 0s/step - loss: 3473.3735 - mae: 3473.3735\n",
      "Epoch 397/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3473.1318 - mae: 3473.1318\n",
      "Epoch 398/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3471.8794 - mae: 3471.8794\n",
      "Epoch 399/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3473.8762 - mae: 3473.8762\n",
      "Epoch 400/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3473.5881 - mae: 3473.5881\n",
      "Epoch 401/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3471.8628 - mae: 3471.8628\n",
      "Epoch 402/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.8113 - mae: 3472.8113\n",
      "Epoch 403/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.7385 - mae: 3472.7385\n",
      "Epoch 404/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.4646 - mae: 3471.4646\n",
      "Epoch 405/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.7356 - mae: 3472.7356\n",
      "Epoch 406/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.7375 - mae: 3472.7375\n",
      "Epoch 407/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3471.6980 - mae: 3471.6980\n",
      "Epoch 408/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.1716 - mae: 3472.1716\n",
      "Epoch 409/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3473.2417 - mae: 3473.2417\n",
      "Epoch 410/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.3357 - mae: 3473.3357\n",
      "Epoch 411/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.6516 - mae: 3473.6516\n",
      "Epoch 412/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.1511 - mae: 3473.1511\n",
      "Epoch 413/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3472.4509 - mae: 3472.4509\n",
      "Epoch 414/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3474.1970 - mae: 3474.1970\n",
      "Epoch 415/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.8118 - mae: 3471.8118\n",
      "Epoch 416/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.5789 - mae: 3471.5789\n",
      "Epoch 417/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.8218 - mae: 3471.8218\n",
      "Epoch 418/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.0815 - mae: 3473.0815\n",
      "Epoch 419/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.0833 - mae: 3472.0833\n",
      "Epoch 420/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3472.7961 - mae: 3472.7961\n",
      "Epoch 421/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3475.1829 - mae: 3475.1829\n",
      "Epoch 422/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.0381 - mae: 3472.0381\n",
      "Epoch 423/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.6821 - mae: 3473.6821\n",
      "Epoch 424/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.5630 - mae: 3472.5630\n",
      "Epoch 425/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.1467 - mae: 3472.1467\n",
      "Epoch 426/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3474.2095 - mae: 3474.2095\n",
      "Epoch 427/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3473.0376 - mae: 3473.0376\n",
      "Epoch 428/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.9731 - mae: 3471.9731\n",
      "Epoch 429/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.8235 - mae: 3472.8235\n",
      "Epoch 430/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.5354 - mae: 3472.5354\n",
      "Epoch 431/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.7002 - mae: 3471.7002\n",
      "Epoch 432/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.3672 - mae: 3472.3672\n",
      "Epoch 433/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3475.0378 - mae: 3475.0378\n",
      "Epoch 434/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3473.0281 - mae: 3473.0281\n",
      "Epoch 435/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3474.2886 - mae: 3474.2886\n",
      "Epoch 436/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.5928 - mae: 3472.5928\n",
      "Epoch 437/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.9714 - mae: 3473.9714\n",
      "Epoch 438/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3474.1279 - mae: 3474.1279\n",
      "Epoch 439/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3471.7244 - mae: 3471.7244\n",
      "Epoch 440/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3473.0535 - mae: 3473.0535\n",
      "Epoch 441/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.1245 - mae: 3472.1245\n",
      "Epoch 442/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.7542 - mae: 3471.7542\n",
      "Epoch 443/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.6372 - mae: 3473.6372\n",
      "Epoch 444/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.7673 - mae: 3473.7673\n",
      "Epoch 445/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3470.5513 - mae: 3470.5513\n",
      "Epoch 446/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3474.2522 - mae: 3474.2522\n",
      "Epoch 447/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3471.6548 - mae: 3471.6548\n",
      "Epoch 448/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.0710 - mae: 3473.0710\n",
      "Epoch 449/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3474.8398 - mae: 3474.8398\n",
      "Epoch 450/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.0569 - mae: 3473.0569\n",
      "Epoch 451/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.4629 - mae: 3473.4629\n",
      "Epoch 452/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3472.3318 - mae: 3472.3318\n",
      "Epoch 453/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3472.3015 - mae: 3472.3015\n",
      "Epoch 454/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.5496 - mae: 3472.5496\n",
      "Epoch 455/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.3235 - mae: 3472.3235\n",
      "Epoch 456/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.7842 - mae: 3473.7842\n",
      "Epoch 457/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3473.3298 - mae: 3473.3298\n",
      "Epoch 458/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.1079 - mae: 3472.1079\n",
      "Epoch 459/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3472.4951 - mae: 3472.4951\n",
      "Epoch 460/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3472.8999 - mae: 3472.8999\n",
      "Epoch 461/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.2991 - mae: 3471.2991\n",
      "Epoch 462/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.2834 - mae: 3473.2834\n",
      "Epoch 463/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.0518 - mae: 3472.0518\n",
      "Epoch 464/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.9478 - mae: 3471.9478\n",
      "Epoch 465/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3473.3408 - mae: 3473.3408\n",
      "Epoch 466/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3471.6855 - mae: 3471.6855\n",
      "Epoch 467/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.8120 - mae: 3472.8120\n",
      "Epoch 468/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.0388 - mae: 3472.0388\n",
      "Epoch 469/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.1067 - mae: 3472.1067\n",
      "Epoch 470/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.5220 - mae: 3472.5220\n",
      "Epoch 471/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3475.0625 - mae: 3475.0625\n",
      "Epoch 472/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3472.1494 - mae: 3472.1494\n",
      "Epoch 473/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3472.5991 - mae: 3472.5991\n",
      "Epoch 474/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.1169 - mae: 3472.1169\n",
      "Epoch 475/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 459us/step - loss: 3473.3750 - mae: 3473.3750\n",
      "Epoch 476/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.1262 - mae: 3472.1262\n",
      "Epoch 477/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3474.0190 - mae: 3474.0190\n",
      "Epoch 478/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3471.9443 - mae: 3471.9443\n",
      "Epoch 479/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3473.4634 - mae: 3473.4634\n",
      "Epoch 480/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.4573 - mae: 3472.4573\n",
      "Epoch 481/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.5947 - mae: 3472.5947\n",
      "Epoch 482/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.4050 - mae: 3473.4050\n",
      "Epoch 483/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.1221 - mae: 3473.1221\n",
      "Epoch 484/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.5938 - mae: 3472.5938\n",
      "Epoch 485/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3472.6987 - mae: 3472.6987\n",
      "Epoch 486/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3476.3044 - mae: 3476.3044\n",
      "Epoch 487/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.4976 - mae: 3473.4976\n",
      "Epoch 488/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3471.2283 - mae: 3471.2283\n",
      "Epoch 489/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3472.2654 - mae: 3472.2654\n",
      "Epoch 490/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3473.3289 - mae: 3473.3289\n",
      "Epoch 491/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 3473.3921 - mae: 3473.3921\n",
      "Epoch 492/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3471.8489 - mae: 3471.8489\n",
      "Epoch 493/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.0681 - mae: 3472.0681\n",
      "Epoch 494/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3472.6689 - mae: 3472.6689\n",
      "Epoch 495/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3473.4929 - mae: 3473.4929\n",
      "Epoch 496/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3471.9255 - mae: 3471.9255\n",
      "Epoch 497/500\n",
      "34/34 [==============================] - 0s 0s/step - loss: 3473.1069 - mae: 3473.1069\n",
      "Epoch 498/500\n",
      "34/34 [==============================] - 0s 191us/step - loss: 3473.4084 - mae: 3473.4084\n",
      "Epoch 499/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 3474.9685 - mae: 3474.9685\n",
      "Epoch 500/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 3477.3557 - mae: 3477.3557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a7a0bc4a00>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Now the data is normalized and One hot encoded. Now lets build our model.\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "insurance_model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "insurance_model_4.compile(loss= tf.keras.losses.mae,\n",
    "                         #optimizer=tf.keras.optimizers.SGD(),\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                         metrics=[\"mae\"])\n",
    "\n",
    "insurance_model_4.fit(X_train_normal, y_train, epochs=500) ## We put new data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "three-lewis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 0s/step - loss: 3471.4602 - mae: 3471.4602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3471.460205078125, 3471.460205078125]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model_4.evaluate(X_train_normal,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "owned-wrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 0s/step - loss: 3161.0383 - mae: 3161.0383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3161.038330078125, 3161.038330078125]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model_4.evaluate(X_test_normal,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-guest",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
